{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tft import MyGatedResidualNetwork, MyResampleNorm\n",
    "\n",
    "class MyVariableSelectionNetwork(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_sizes: Dict[str, int],\n",
    "        hidden_size: int,\n",
    "        input_embedding_flags: Dict[str, bool] = {},\n",
    "        dropout: float = 0.1,\n",
    "        context_size: int = None,\n",
    "        single_variable_grns: Dict[str, MyGatedResidualNetwork] = {},\n",
    "        prescalers: Dict[str, nn.Linear] = {},\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Calculate weights for ``num_inputs`` variables  which are each of size ``input_size``\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_sizes = input_sizes\n",
    "        self.input_embedding_flags = input_embedding_flags\n",
    "        self.dropout = dropout\n",
    "        self.context_size = context_size\n",
    "\n",
    "        if self.num_inputs > 1:\n",
    "            if self.context_size is not None:\n",
    "                self.flattened_grn = MyGatedResidualNetwork(\n",
    "                    self.input_size_total,\n",
    "                    min(self.hidden_size, self.num_inputs),\n",
    "                    self.num_inputs,\n",
    "                    self.dropout,\n",
    "                    self.context_size,\n",
    "                    residual=False,\n",
    "                )\n",
    "            else:\n",
    "                self.flattened_grn = MyGatedResidualNetwork(\n",
    "                    self.input_size_total,\n",
    "                    min(self.hidden_size, self.num_inputs),\n",
    "                    self.num_inputs,\n",
    "                    self.dropout,\n",
    "                    residual=False,\n",
    "                )\n",
    "\n",
    "        self.single_variable_grns = nn.ModuleDict()\n",
    "        self.prescalers = nn.ModuleDict()\n",
    "        for name, input_size in self.input_sizes.items():\n",
    "            if name in single_variable_grns:\n",
    "                self.single_variable_grns[name] = single_variable_grns[name]\n",
    "            elif self.input_embedding_flags.get(name, False):\n",
    "                self.single_variable_grns[name] = MyResampleNorm(\n",
    "                    input_size, self.hidden_size\n",
    "                )\n",
    "            else:\n",
    "                self.single_variable_grns[name] = MyGatedResidualNetwork(\n",
    "                    input_size,\n",
    "                    min(input_size, self.hidden_size),\n",
    "                    output_size=self.hidden_size,\n",
    "                    dropout=self.dropout,\n",
    "                )\n",
    "            if name in prescalers:  # reals need to be first scaled up\n",
    "                self.prescalers[name] = prescalers[name]\n",
    "            elif not self.input_embedding_flags.get(name, False):\n",
    "                self.prescalers[name] = nn.Linear(1, input_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    @property\n",
    "    def input_size_total(self):\n",
    "        return sum(\n",
    "            size if name in self.input_embedding_flags else size\n",
    "            for name, size in self.input_sizes.items()\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def num_inputs(self):\n",
    "        return len(self.input_sizes)\n",
    "\n",
    "    def forward(self, x: Dict[str, torch.Tensor], context: torch.Tensor = None):\n",
    "        if self.num_inputs > 1:\n",
    "            # transform single variables\n",
    "            var_outputs = []\n",
    "            weight_inputs = []\n",
    "            for name in self.input_sizes.keys():\n",
    "                # select embedding belonging to a single input\n",
    "                variable_embedding = x[name]\n",
    "                if name in self.prescalers:\n",
    "                    variable_embedding = self.prescalers[name](variable_embedding)\n",
    "                weight_inputs.append(variable_embedding)\n",
    "                var_outputs.append(self.single_variable_grns[name](variable_embedding))\n",
    "            var_outputs = torch.stack(var_outputs, dim=-1)\n",
    "\n",
    "            # calculate variable weights\n",
    "            ## get all of the embeddings from all of the variables and just combine them, very simple\n",
    "            flat_embedding = torch.cat(weight_inputs, dim=-1)\n",
    "            #\n",
    "            sparse_weights = self.flattened_grn(flat_embedding, context)\n",
    "            sparse_weights = self.softmax(sparse_weights).unsqueeze(-2)\n",
    "\n",
    "            outputs = var_outputs * sparse_weights\n",
    "            outputs = outputs.sum(dim=-1)\n",
    "\n",
    "        else:  # for one input, do not perform variable selection, just encoding\n",
    "            pass\n",
    "            \n",
    "\n",
    "        # the outputs are a weighted sum of the importance of each variable for the current time step?\n",
    "        return outputs, sparse_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([8, 64])\n",
      "Weights shape: torch.Size([8, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "x = {\n",
    "    \"fueltype\": torch.tensor(\n",
    "        [\n",
    "            [1.3122, 2.0916, 0.4749, 2.5620, -2.2733],\n",
    "            [0.3703, -1.0351, -0.2936, 1.7159, 0.6043],\n",
    "            [0.6815, -0.5216, -0.5855, -1.4212, 0.9495],\n",
    "            [-0.4051, -1.1760, 0.8423, -0.3982, 0.0264],\n",
    "            [1.6051, 1.6294, -1.8574, -0.9640, -0.3509],\n",
    "            [0.5635, -1.2075, -0.0809, -1.2652, -0.8209],\n",
    "            [-2.4415, -0.5139, -0.5364, -0.1024, 0.3291],\n",
    "            [0.5885, 0.1993, -1.9647, -0.0054, -1.3004],\n",
    "        ],\n",
    "        device=\"cpu\",\n",
    "    ),\n",
    "    \"encoder_length\": torch.tensor(\n",
    "        [[1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0], [1.0]], device=\"cpu\"\n",
    "    ),\n",
    "    \"value_center\": torch.tensor(\n",
    "        [\n",
    "            [0.5803],\n",
    "            [1.6990],\n",
    "            [1.4191],\n",
    "            [-0.8215],\n",
    "            [-0.7555],\n",
    "            [-0.8013],\n",
    "            [-0.7047],\n",
    "            [-0.6153],\n",
    "        ],\n",
    "        device=\"cpu\",\n",
    "    ),\n",
    "    \"value_scale\": torch.tensor(\n",
    "        [\n",
    "            [1.3127],\n",
    "            [2.0438],\n",
    "            [-0.2789],\n",
    "            [-0.7635],\n",
    "            [-0.7440],\n",
    "            [-0.6782],\n",
    "            [-0.5635],\n",
    "            [-0.3283],\n",
    "        ],\n",
    "        device=\"cpu\",\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "device = torch.device(\"cpu\")  # or torch.device('cuda') if using GPU and it's available\n",
    "\n",
    "x = {name: tensor.to(device) for name, tensor in x.items()}\n",
    "\n",
    "# Create an instance of MyVariableSelectionNetwork\n",
    "vsn = MyVariableSelectionNetwork(\n",
    "    input_sizes={'fueltype': 5, 'encoder_length': 16, 'value_center': 16, 'value_scale': 16},\n",
    "    hidden_size=64,\n",
    "    input_embedding_flags={'fueltype':True},\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "vsn.to(device)\n",
    "\n",
    "\n",
    "outputs, weights = vsn(x)\n",
    "\n",
    "# Print the shapes of the outputs and weights\n",
    "print(\"Outputs shape:\", outputs.shape)\n",
    "print(\"Weights shape:\", weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1079, -0.1849, -0.0550,  0.1918,  0.1365,  0.3658,  0.4432,  0.3992,\n",
       "         0.7487,  0.7473,  0.7420,  0.6947,  0.6873,  0.4913,  0.4800,  0.5437,\n",
       "         0.8107,  0.4517,  0.7231,  0.4370,  0.5048,  0.1436,  0.2879,  0.1371,\n",
       "         0.0751,  0.1137, -0.1464, -0.2281, -0.3206, -0.3082, -0.3979, -0.3520,\n",
       "        -0.1593, -0.0053,  0.2898, -0.0181, -0.0355, -0.2747, -0.2707,  0.0326,\n",
       "         0.1103,  0.0876,  0.1589,  0.1618,  0.1073,  0.0519,  0.2245,  0.4107,\n",
       "         0.3577,  0.2566, -0.0041, -0.0374, -0.0417, -0.1023, -0.1377, -0.1823,\n",
       "        -0.3507, -0.5448, -0.7976, -0.8944, -1.1224, -1.5733, -1.9310, -2.0214],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6045, 0.0711, 0.2730, 0.0514]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
